{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Evaluation Metrics from the Scratch\n",
    "## and comparing the results with sklearn\n",
    "<ul>\n",
    "    <li>Confusion Matrix</li>\n",
    "    <li>Accuracy</li>\n",
    "    <li>Precision</li>\n",
    "    <li>Recall</li>\n",
    "    <li>F1-Score</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15758, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_pred_random_forest</th>\n",
       "      <th>y_pred_logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.531904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>0.414496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>0.569883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506616</td>\n",
       "      <td>0.443674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418302</td>\n",
       "      <td>0.369532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_act  y_pred_random_forest  y_pred_logistic\n",
       "0      1              0.639816         0.531904\n",
       "1      0              0.490993         0.414496\n",
       "2      1              0.623815         0.569883\n",
       "3      1              0.506616         0.443674\n",
       "4      0              0.418302         0.369532"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "# printing shape of dataframe\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_pred_random_forest</th>\n",
       "      <th>y_pred_logistic</th>\n",
       "      <th>y_pred_rf</th>\n",
       "      <th>y_pred_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.531904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>0.414496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>0.569883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506616</td>\n",
       "      <td>0.443674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418302</td>\n",
       "      <td>0.369532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_act  y_pred_random_forest  y_pred_logistic  y_pred_rf  y_pred_lr\n",
       "0      1              0.639816         0.531904          1          1\n",
       "1      0              0.490993         0.414496          0          0\n",
       "2      1              0.623815         0.569883          1          1\n",
       "3      1              0.506616         0.443674          1          0\n",
       "4      0              0.418302         0.369532          0          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values below 0.5 will be 0\n",
    "# values above 0.5 will be 1\n",
    "# hence declaring the threshold\n",
    "thresh = 0.5\n",
    "\n",
    "# converting 2 columns according to the threshold\n",
    "df['y_pred_rf'] = (df.y_pred_random_forest >= 0.5).astype('int')\n",
    "df['y_pred_lr'] = (df.y_pred_logistic >= 0.5).astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate true positives, true negatives, false positives, false negatives\n",
    "def compute_tp_tn_fp_fn(y_act,y_pred):\n",
    "    '''\n",
    "    True Positive: actual = 1, predicted = 1\n",
    "    True Negatives: actual = 0, predicted = 0\n",
    "    False Postives: actual = 0, predicted = 1\n",
    "    False Negative: actual = 1, predicted = 0\n",
    "    '''\n",
    "    tp = sum( (y_act == 1) & (y_pred == 1))\n",
    "    tn = sum( (y_act == 0) & (y_pred == 0))\n",
    "    fp = sum( (y_act == 0) & (y_pred == 1))\n",
    "    fn = sum( (y_act == 1) & (y_pred == 0))\n",
    "    return tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP for Logistic Reg : 4279\n",
      "TN for Logistic Reg : 5425\n",
      "FP for Logistic Reg : 2454\n",
      "FN for Logistic Reg : 3600\n"
     ]
    }
   ],
   "source": [
    "# finding tp,tn,fp,fn for Logistic regression prediction scores using \n",
    "# manually made function\n",
    "tp_lr, tn_lr, fp_lr, fn_lr = compute_tp_tn_fp_fn(\\\n",
    "                                df.y_act,df.y_pred_lr)\n",
    "print('TP for Logistic Reg :', tp_lr)\n",
    "print('TN for Logistic Reg :', tn_lr)\n",
    "print('FP for Logistic Reg :', fp_lr)\n",
    "print('FN for Logistic Reg :', fn_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP for Random Forest : 5047\n",
      "TN for Random Forest : 5519\n",
      "FP for Random Forest : 2360\n",
      "FN for Random Forest : 2832\n"
     ]
    }
   ],
   "source": [
    "# finding tp,tn,fp,fn for Random Forest prediction scores using\n",
    "# manually made function\n",
    "tp_rf, tn_rf, fp_rf, fn_rf = compute_tp_tn_fp_fn(df.y_act, df.y_pred_rf)\n",
    "print('TP for Random Forest :', tp_rf)\n",
    "print('TN for Random Forest :', tn_rf)\n",
    "print('FP for Random Forest :', fp_rf)\n",
    "print('FN for Random Forest :', fn_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing confusion matrix from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# obtaining tp,tn,fp,fn from the confusion matrix formed by sklearn\n",
    "tn_rf1, fp_rf1, fn_rf1, tp_rf1 = confusion_matrix(df.y_act, df.y_pred_rf).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP for Random Forest : 5047\n",
      "TN for Random Forest : 5519\n",
      "FP for Random Forest : 2360\n",
      "FN for Random Forest : 2832\n"
     ]
    }
   ],
   "source": [
    "# printing tp,tn,fp,fn for Random Forest using sklearn\n",
    "print('TP for Random Forest :', tp_rf1)\n",
    "print('TN for Random Forest :', tn_rf1)\n",
    "print('FP for Random Forest :', fp_rf1)\n",
    "print('FN for Random Forest :', fn_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to compute accuracy\n",
    "def compute_accuracy(tp,tn,fp,fn):\n",
    "    '''\n",
    "    Accuracy = tp+tn/tp+tn+fp+fn\n",
    "    '''\n",
    "    return ((tp+tn)*100)/float(tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression : 61.58141896179718\n",
      "Accuracy for random forest : 67.05165630156111\n"
     ]
    }
   ],
   "source": [
    "# printing the accuracy scores of Logistic Regression & Random Forest\n",
    "# using the user-made function\n",
    "print('Accuracy for logistic regression :',\\\n",
    "     compute_accuracy(tp_lr,tn_lr,fp_lr,fn_lr))\n",
    "print('Accuracy for random forest :',\\\n",
    "     compute_accuracy(tp_rf,tn_rf,fp_rf,fn_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression :  61.58141896179718\n",
      "Accuracy for random forest :  67.05165630156111\n"
     ]
    }
   ],
   "source": [
    "# printing the accuracy scores of Logistic Regression & Random Forest\n",
    "# using the sklearn's accuracy_score function\n",
    "print('Accuracy for logistic regression : ',\\\n",
    "     100*accuracy_score(df.y_act,df.y_pred_lr))\n",
    "print('Accuracy for random forest : ',\\\n",
    "     100*accuracy_score(df.y_act,df.y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to compute precision\n",
    "def compute_precision(tp,fp):\n",
    "    '''\n",
    "    precision = tp/tp+fp\n",
    "    '''\n",
    "    return (tp*100)/float(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Logistic Regression:  63.55265112134264\n",
      "Precision for Random Forest:  68.1382476036182\n"
     ]
    }
   ],
   "source": [
    "# printing the precision of Logistic Regression & Random Forest\n",
    "# using the user-made function\n",
    "print('Precision for Logistic Regression: ',\\\n",
    "     compute_precision(tp_lr,fp_lr))\n",
    "print('Precision for Random Forest: ',\\\n",
    "     compute_precision(tp_rf,fp_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Logistic Regression : 63.55265112134264\n",
      "Precision for Random Forest : 68.1382476036182\n"
     ]
    }
   ],
   "source": [
    "# importing precision_score from sklearn\n",
    "from sklearn.metrics import precision_score\n",
    "# printing the precision of Logistic Regression & Random Forest\n",
    "# using the sklearn's precision function\n",
    "print('Precision for Logistic Regression :', \\\n",
    "      100* precision_score(df.y_act, df.y_pred_lr))\n",
    "print('Precision for Random Forest :',\\\n",
    "      100* precision_score(df.y_act,df.y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to compute recall\n",
    "def compute_recall(tp,fn):\n",
    "    '''\n",
    "    precision = tp/tp+fn\n",
    "    '''\n",
    "    return (tp*100)/float(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Logistic Regression:  54.30892245208783\n",
      "Precision for Random Forest:  64.05635232897576\n"
     ]
    }
   ],
   "source": [
    "# printing the recall of Logistic Regression & Random Forest\n",
    "# using the user-made function\n",
    "print('Recall for Logistic Regression: ',\\\n",
    "     compute_recall(tp_lr,fn_lr))\n",
    "print('Recall for Random Forest: ',\\\n",
    "     compute_recall(tp_rf,fn_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Logistic Regression : 54.30892245208783\n",
      "Recall for Random Forest : 64.05635232897576\n"
     ]
    }
   ],
   "source": [
    "# importing recall_score from sklearn\n",
    "from sklearn.metrics import recall_score\n",
    "# printing the recall of Logistic Regression & Random Forest\n",
    "# using the sklearn's recall function\n",
    "print('Recall for Logistic Regression :', \\\n",
    "      100* recall_score(df.y_act, df.y_pred_lr))\n",
    "print('Recall for Random Forest :',\\\n",
    "      100* recall_score(df.y_act,df.y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to compute f1 score\n",
    "def compute_f1_score(y_true,y_pred):\n",
    "    # calculates f1 score\n",
    "    tp,tn,fp,fn = compute_tp_tn_fp_fn(y_true,y_pred)\n",
    "    precision = compute_precision(tp, fp)/100\n",
    "    recall = compute_recall(tp, fn)/100\n",
    "    f1_score = (2*precision*recall)/(recall+precision)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistic Regression : 0.5856830002737475\n",
      "F1 score for Random Forest : 0.660342797330891\n"
     ]
    }
   ],
   "source": [
    "# printing the f1-score of Logistic Regression & Random Forest\n",
    "# using the user-made function\n",
    "print('F1 score for Logistic Regression :', compute_f1_score(df.y_act, \n",
    "                                                             df.y_pred_lr))\n",
    "print('F1 score for Random Forest :', compute_f1_score(df.y_act, \n",
    "                                                             df.y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistic Regression : 0.5856830002737475\n",
      "F1 score for Random Forest : 0.660342797330891\n"
     ]
    }
   ],
   "source": [
    "# importing f1_score from sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "# printing the f1-score of Logistic Regression & Random Forest\n",
    "# using the sklearn's f1_score function\n",
    "print('F1 score for Logistic Regression :', f1_score(df.y_act, df.y_pred_lr))\n",
    "print('F1 score for Random Forest :', f1_score(df.y_act, df.y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
